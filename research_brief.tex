\documentclass[11pt]{article}
\usepackage[margin=1in]{geometry}
\usepackage{parskip}
\usepackage{graphicx}
\usepackage{titlesec}
\usepackage{url}
\usepackage{natbib}

\titleformat{\section}{\large\bfseries}{\thesection}{1em}{}
\titlespacing*{\section}{0pt}{1ex}{0.5ex}

\begin{document}

\begin{center}
{\LARGE \textbf{Feng Lab: Clinical AI Innovation and Research for All}}
\end{center}

\begin{figure}
	\vspace{-1.3cm}
	\centering
	\includegraphics[width=0.9\linewidth]{virtuous_cycle_v2.png}
	\vspace{-0.4cm}
\end{figure}

Artificial Intelligence (AI) is now transforming healthcare.
At the Zuckerberg San Francisco General Hospital (ZSFG), our group serves as data science arm of the digital innovation team and has shown how AI, when done thoughtfully, can do immense good.
Over the past four years, we have helped ZSFG become a leader in developing clinical AI solutions for vulnerable and underserved populations.
Our AI-based readmission system reduced the hospital's 30-day unplanned readmission rate from one of the highest rates among California safety-net hospitals to one of the lowest---saving \$7.2 million in at-risk pay-for-performance funding and, more importantly, keeping patients healthy at home \citep{Bennett2025-tp}.
Our AI-powered dashboard automatically summarizes complex medical charts to surface medical-social needs and is anticipated to increase social work efficiency by over 50\% \citep{Kothari2026-zo}.
These successes have convinced hospital leadership to now leverage AI across an increasing range of quality improvement tasks.
Our work has also received numerous awards, including from the California Association of Public Hospitals and Health Systems Safety Net Institute and the Joint Commission's Award for Excellence in Pursuit of Healthcare Equity.

At the same time, it is paramount we address and remain vigilant regarding the major risks posed by AI, particularly when one is developing AI solutions for vulnerable and underserved populations.
Consequently, our lab is simultaneously dedicated to developing methods that ensure the safety and reliability of AI systems.
Thus, our lab runs two parallel efforts: build AI tools and research AI methods.
These two arms inform each other to embody a Learning Healthcare System, where real-world challenges inform our research and our research drives translational impact.

To ensure our research meets the highest standards of rigor, we collaborate closely with the US Food and Drug Administration to develop new methods and frameworks for evaluating and monitoring AI systems.
Together, our group has become a leader in AI monitoring, publishing landmark papers on quality improvement frameworks for AI oversight \citep{Feng2022-mk} and novel methods guaranteed to detect performance deterioration in a timely fashion \citep{Feng2024-yr,Feng2024-zz}.
Given the rapid rise of generative AI tools, we are also now working with the FDA to research regulatory-grade methods for evaluating free-form outputs from these systems \citep{Vossler2026-ii}.
More broadly, in our effort to democratize regulatory science research, we have released open-source pipelines enabling anyone to analyze and extract information from regulatory documents at scale \citep{Li2026-sg}.

Looking ahead, we aim to scale our clinical AI tools beyond ZSFG to other safety-net hospitals, while training the next generation of researchers who can bridge AI and clinical practice.
Our vision is that by working together--having research inform clinical practice and vice versa--we can make clinical AI systems that benefit everyone.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\bibliographystyle{unsrt}
\bibliography{research_brief}

\end{document}
